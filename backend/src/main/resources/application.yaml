server:
  port: 8080

spring:
  application:
    name: backend
  http:
    client:
      connect-timeout: ${HTTP_CLIENT_CONNECT_TIMEOUT:PT45S}
      read-timeout: ${HTTP_CLIENT_READ_TIMEOUT:PT10M}
    reactiveclient:
      connect-timeout: ${HTTP_REACTIVE_CLIENT_CONNECT_TIMEOUT:${HTTP_CLIENT_CONNECT_TIMEOUT:PT45S}}
      read-timeout: ${HTTP_REACTIVE_CLIENT_READ_TIMEOUT:${HTTP_CLIENT_READ_TIMEOUT:PT10M}}
  ai:
    tools:
      observations:
        include-content: true   # ⚠️ может содержать чувствительные данные
    chat:
      client:
        enabled: false
        observations:
          log-prompt: true      # вывести собранный prompt
      observations:
        log-prompt: true        # вывести prompt на уровне ChatModel
        log-completion: true    # вывести completion
    mcp:
      client:
        enabled: ${PERPLEXITY_MCP_ENABLED:true}
        name: perplexity-mcp-client
        request-timeout: 600s
        type: SYNC
        toolcallback:
          enabled: true
        annotation-scanner:
          enabled: false
        stdio:
          connections:
            perplexity:
              command: perplexity-mcp   # глобальный бинарь из /usr/local/bin
              args: []                                        # обычно без аргументов
              env:
                PERPLEXITY_API_KEY: ${PERPLEXITY_API_KEY:demo-perplexity-key}
        streamable-http:
          connections:
            agentops:
              url: ${AGENT_OPS_MCP_HTTP_BASE_URL:http://localhost:7091}
              endpoint: ${AGENT_OPS_MCP_HTTP_ENDPOINT:/mcp}
            flowops:
              url: ${FLOW_OPS_MCP_HTTP_BASE_URL:http://localhost:7092}
              endpoint: ${FLOW_OPS_MCP_HTTP_ENDPOINT:/mcp}
            insight:
              url: ${INSIGHT_MCP_HTTP_BASE_URL:http://localhost:7093}
              endpoint: ${INSIGHT_MCP_HTTP_ENDPOINT:/mcp}
            github:
              url: ${GITHUB_MCP_HTTP_BASE_URL:http://localhost:7094}
              endpoint: ${GITHUB_MCP_HTTP_ENDPOINT:/mcp}
            docker:
              url: ${DOCKER_MCP_HTTP_BASE_URL:http://localhost:7095}
              endpoint: ${DOCKER_MCP_HTTP_ENDPOINT:/mcp}
            repo-analysis:
              url: ${REPO_ANALYSIS_MCP_HTTP_BASE_URL:http://localhost:7096}
              endpoint: ${REPO_ANALYSIS_MCP_HTTP_ENDPOINT:/mcp}
            notes:
              url: ${NOTES_MCP_HTTP_BASE_URL:http://localhost:7097}
              endpoint: ${NOTES_MCP_HTTP_ENDPOINT:/mcp}
            coding:
              url: ${CODING_MCP_HTTP_BASE_URL:http://localhost:7098}
              endpoint: ${CODING_MCP_HTTP_ENDPOINT:/mcp}
    openai:
      api-key: ${OPENAI_API_KEY:demo-openai-key}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
      client:
        read-timeout: ${OPENAI_CLIENT_READ_TIMEOUT:${HTTP_CLIENT_READ_TIMEOUT:PT10M}}
      chat:
        options:
          model: ${OPENAI_DEFAULT_MODEL:gpt-4o-mini}
          temperature: ${OPENAI_TEMPERATURE:0.7}
          top-p: ${OPENAI_TOP_P:1.0}
          max-tokens: ${OPENAI_MAX_TOKENS:1024}
      log-request: true
      log-response: true
    zhipuai:
      api-key: ${ZHIPU_API_KEY:demo-zhipu-key}
      base-url: ${ZHIPU_BASE_URL:https://api.z.ai}
      client:
        read-timeout: ${ZHIPU_CLIENT_READ_TIMEOUT:${HTTP_CLIENT_READ_TIMEOUT:PT10M}}
      chat:
        completions-path: ${ZHIPU_COMPLETIONS_PATH:/api/paas/v4/chat/completions}
        options:
          model: ${ZHIPU_DEFAULT_MODEL:glm-4.6}
          temperature: ${ZHIPU_TEMPERATURE:0.7}
          top-p: ${ZHIPU_TOP_P:0.95}
          max-tokens: ${ZHIPU_MAX_TOKENS:1024}

management:
  tracing:
    enabled: true
    sampling:
      probability: 1.0
    logging:
      enabled: true          # выводить трейсы в логи

springdoc:
  api-docs:
    enabled: true
  swagger-ui:
    displayRequestDuration: true
    tagsSorter: alpha

logging:
  level:
    com.aiadvent: DEBUG
    com.aiadvent.backend.chat: DEBUG
    com.aiadvent.backend.mcp: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.web: INFO
    ConstructorAudit: INFO

    # обязательно DEBUG для обработчика наблюдений, иначе логи не увидишь
    org.springframework.ai.model.chat.observation: DEBUG
    org.springframework.ai.chat: DEBUG

    # tool calling в целом
    org.springframework.ai.model.tool: DEBUG
    org.springframework.ai.tool: DEBUG
    org.springframework.ai.tool.method: DEBUG
    org.springframework.ai.tool.executor: DEBUG
    org.springframework.ai.tool.convert: DEBUG

    # MCP-уровень (важно для perplexity_search)
    org.springframework.ai.mcp: DEBUG
    org.springframework.ai.mcp.client: DEBUG
    org.springframework.ai.mcp.tool: DEBUG
    com.aiadvent.backend.mcp.service.McpCatalogService: WARN
    com.aiadvent.backend.flow.tool.service.McpToolBindingService: INFO

    # чтобы видеть обмен с моделью и LoggingChatModel
    org.springframework.ai.chat.model: DEBUG
    org.springframework.ai.chat.client.advisor: DEBUG
    com.aiadvent.backend.chat.logging: DEBUG

app:
  chat:
    research:
      system-prompt: |
        You are a meticulous research analyst. Use the configured MCP tools to collect current
        information, enrich answers with concise insights, and always cite numbered sources like [1].
      structured-advice: |
        При необходимости вызывай подключенные MCP-инструменты, чтобы получить актуальные данные.
        Включай ссылки на источники в поле `details`, оформляя их в формате [n], где n соответствует номеру источника.
        Если инструмент возвращает несколько ссылок, добавь краткое пояснение каждой.
      tools:
        - code: perplexity_search
          schema-version: 1
          execution-mode: AUTO
          request-overrides:
            max_results: 8
        - code: agent_ops.list_agents
          schema-version: 1
          execution-mode: MANUAL
        - code: agent_ops.preview_dependencies
          schema-version: 1
          execution-mode: MANUAL
        - code: agent_ops.register_agent
          schema-version: 1
          execution-mode: MANUAL
        - code: flow_ops.list_flows
          schema-version: 1
          execution-mode: MANUAL
        - code: flow_ops.diff_flow_version
          schema-version: 1
          execution-mode: MANUAL
        - code: flow_ops.publish_flow
          schema-version: 1
          execution-mode: MANUAL
        - code: flow_ops.rollback_flow
          schema-version: 1
          execution-mode: MANUAL
        - code: flow_ops.validate_blueprint
          schema-version: 1
          execution-mode: MANUAL
        - code: insight.recent_sessions
          schema-version: 1
          execution-mode: MANUAL
        - code: insight.fetch_metrics
          schema-version: 1
          execution-mode: MANUAL
        - code: insight.fetch_summary
          schema-version: 1
          execution-mode: MANUAL
        - code: insight.search_memory
          schema-version: 1
          execution-mode: MANUAL
        - code: notes.save_note
          schema-version: 1
          execution-mode: MANUAL
        - code: notes.search_similar
          schema-version: 1
          execution-mode: MANUAL
        - code: repo.rag_index_status
          schema-version: 1
          execution-mode: MANUAL
        - code: repo.rag_search
          schema-version: 1
          execution-mode: MANUAL
        - code: repo.rag_search_global
          schema-version: 1
          execution-mode: MANUAL
        - code: coding.generate_patch
          schema-version: 1
          execution-mode: AUTO
        - code: coding.review_patch
          schema-version: 1
          execution-mode: AUTO
        - code: coding.apply_patch_preview
          schema-version: 1
          execution-mode: MANUAL
        - code: coding.list_patches
          schema-version: 1
          execution-mode: AUTO
        - code: coding.discard_patch
          schema-version: 1
          execution-mode: MANUAL
        - code: github.create_branch
          schema-version: 1
          execution-mode: MANUAL
        - code: github.commit_workspace_diff
          schema-version: 1
          execution-mode: MANUAL
        - code: github.push_branch
          schema-version: 1
          execution-mode: MANUAL
        - code: github.open_pull_request
          schema-version: 1
          execution-mode: MANUAL
        - code: github.approve_pull_request
          schema-version: 1
          execution-mode: MANUAL
        - code: github.merge_pull_request
          schema-version: 1
          execution-mode: MANUAL
      default-tool-codes:
        - perplexity_search
      disabled-tool-namespaces:
        - agent_ops
        - flow_ops
        - insight
    logging:
      model:
        enabled: ${CHAT_LOGGING_MODEL_ENABLED:true}
        log-completion: ${CHAT_LOGGING_MODEL_COMPLETION:true}
      tools:
        enabled: ${CHAT_LOGGING_TOOLS_ENABLED:true}
    memory:
      window-size: ${CHAT_MEMORY_WINDOW_SIZE:20}
      retention: ${CHAT_MEMORY_RETENTION:PT6H}
      cleanup-interval: ${CHAT_MEMORY_CLEANUP_INTERVAL:PT30M}
      summarization:
        enabled: ${CHAT_MEMORY_SUMMARIZATION_ENABLED:false}
        trigger-token-limit: ${CHAT_MEMORY_SUMMARIZATION_TRIGGER:12000}
        target-token-count: ${CHAT_MEMORY_SUMMARIZATION_TARGET:6000}
        model: ${CHAT_MEMORY_SUMMARIZATION_MODEL:openai:gpt-4o-mini}
        max-concurrent-summaries: ${CHAT_MEMORY_SUMMARIZATION_MAX_CONCURRENT:4}
        max-queue-size: ${CHAT_MEMORY_SUMMARIZATION_MAX_QUEUE_SIZE:100}
        retained-messages: ${CHAT_MEMORY_SUMMARY_RETAINED_MESSAGES:200}
        backfill:
          enabled: ${CHAT_MEMORY_SUMMARIZATION_BACKFILL_ENABLED:false}
          min-messages: ${CHAT_MEMORY_SUMMARIZATION_BACKFILL_MIN_MESSAGES:40}
          batch-size: ${CHAT_MEMORY_SUMMARIZATION_BACKFILL_BATCH_SIZE:25}
          max-iterations: ${CHAT_MEMORY_SUMMARIZATION_BACKFILL_MAX_ITERATIONS:20}
    default-provider: zhipu
    providers:
      zhipu:
        type: ZHIPUAI
        display-name: "zhipu.ai"
        base-url: ${ZHIPU_BASE_URL:https://api.z.ai}
        api-key: ${ZHIPU_API_KEY:demo-zhipu-key}
        completions-path: ${ZHIPU_COMPLETIONS_PATH:/api/paas/v4/chat/completions}
        timeout: ${ZHIPU_TIMEOUT:${HTTP_CLIENT_READ_TIMEOUT:PT4M}}
        temperature: ${ZHIPU_TEMPERATURE:0.7}
        top-p: ${ZHIPU_TOP_P:0.95}
        max-tokens: ${ZHIPU_MAX_TOKENS:1024}
        default-model: ${ZHIPU_DEFAULT_MODEL:glm-4.6}
        retry:
          attempts: ${ZHIPU_RETRY_ATTEMPTS:3}
          initial-delay: ${ZHIPU_RETRY_INITIAL_DELAY:250ms}
          multiplier: ${ZHIPU_RETRY_MULTIPLIER:2.0}
          retryable-statuses: ${ZHIPU_RETRY_STATUS_CODES:429,500,502,503,504}
        models:
          "[glm-4.6]":
            display-name: "GLM-4.6"
            tier: pro
            context-window: 81920
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.0006
              output-per-1k-tokens: 0.0022
            usage:
              mode: fallback
              fallback-tokenizer: cl100k_base
          "[glm-4.5]":
            display-name: "GLM-4.5"
            tier: standard
            context-window: 65536
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.00035
              output-per-1k-tokens: 0.00155
            usage:
              mode: fallback
              fallback-tokenizer: cl100k_base
          "[glm-4.5-air]":
            display-name: "GLM-4.5 Air"
            tier: budget
            context-window: 32768
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.0002
              output-per-1k-tokens: 0.0011
            usage:
              mode: fallback
              fallback-tokenizer: cl100k_base
          "[glm-4-32b-0414-128k]":
            display-name: "GLM-4 32B 0414 (128K)"
            tier: flagship
            context-window: 128000
            sync-enabled: true
            streaming-enabled: false
            structured-enabled: false
            pricing:
              input-per-1k-tokens: 0.0001
              output-per-1k-tokens: 0.0001
            usage:
              mode: fallback
        fallback-tokenizer: cl100k_base
      openai:
        type: OPENAI
        display-name: "OpenAI"
        base-url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
        api-key: ${OPENAI_API_KEY:demo-openai-key}
        timeout: ${OPENAI_TIMEOUT:PT2M}
        temperature: ${OPENAI_TEMPERATURE:0.7}
        top-p: ${OPENAI_TOP_P:1.0}
        max-tokens: ${OPENAI_MAX_TOKENS:1024}
        default-model: ${OPENAI_DEFAULT_MODEL:gpt-4o-mini}
        retry:
          attempts: ${OPENAI_RETRY_ATTEMPTS:3}
          initial-delay: ${OPENAI_RETRY_INITIAL_DELAY:250ms}
          multiplier: ${OPENAI_RETRY_MULTIPLIER:2.0}
          retryable-statuses: ${OPENAI_RETRY_STATUS_CODES:429,500,502,503,504}
        models:
          gpt-5-nano:
            display-name: "GPT-5 Nano"
            tier: economy
            context-window: 128000
            max-output-tokens: 8192
            use-completion-tokens: true
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.00005
              output-per-1k-tokens: 0.0004
            usage:
              mode: native
          gpt-4o-mini:
            display-name: "GPT-4o Mini"
            tier: budget
            context-window: 128000
            max-output-tokens: 16384
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.00015
              output-per-1k-tokens: 0.0006
            usage:
              mode: native
          gpt-4o:
            display-name: "GPT-4o"
            tier: pro
            context-window: 128000
            max-output-tokens: 16384
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.0025
              output-per-1k-tokens: 0.01
            usage:
              mode: native
          gpt-5:
            display-name: "GPT-5"
            tier: flagship
            context-window: 200000
            max-output-tokens: 32768
            use-completion-tokens: true
            sync-enabled: true
            pricing:
              input-per-1k-tokens: 0.00125
              output-per-1k-tokens: 0.01
            usage:
              mode: native

  mcp:
    catalog:
      servers:
        perplexity:
          display-name: "Perplexity MCP"
          description: "Поисковый и research-сервер Perplexity (search / deep research)."
          tags: ["search", "research"]
          security-policy: "external-readonly"
        agentops:
          display-name: "Agent Ops MCP"
          description: "Управление каталогом агентов: регистрация, просмотр и диагностика зависимостей."
          tags: ["agents", "operations"]
          security-policy: "internal-admin"
        flowops:
          display-name: "Flow Ops MCP"
          description: "Инструменты для управления и публикации flow-definition."
          tags: ["flows", "operations"]
          security-policy: "internal-change-managed"
        insight:
          display-name: "Insight MCP"
          description: "Аналитика сессий чатов и flow: summary, поиск по памяти, метрики."
          tags: ["analytics", "observability"]
          security-policy: "internal-readonly"
        github:
          display-name: "GitHub MCP"
          description: "Инструменты чтения репозиториев GitHub, подготовка данных для анализа PR."
          tags: ["github", "code-review"]
          security-policy: "external-restricted"
        docker:
          display-name: "Docker Runner MCP"
          description: "Контейнеризированный запуск Gradle-тестов в изолированном окружении."
          tags: ["ci", "gradle"]
          security-policy: "internal-change-managed"
        repo-analysis:
          display-name: "Repo Analysis MCP"
          description: "Анализ локального workspace: скан сегментов, агрегация находок и hotspots."
          tags: ["analysis", "workspace"]
          security-policy: "internal-readonly"
        notes:
          display-name: "Notes MCP"
          description: "Хранение пользовательских заметок и поиск похожего контента через PgVector."
          tags: ["notes", "rag"]
          security-policy: "internal-readonly"
        coding-mcp:
          display-name: "Coding MCP"
          description: "Ассистент по генерации, ревью и dry-run патчей в подготовленном workspace."
          tags: ["coding", "patch", "github"]
          security-policy: "internal-change-managed"

  flow:
    api:
      v2-enabled: ${FLOW_API_V2_ENABLED:false}
    migration:
      cli:
        enabled: ${FLOW_MIGRATION_CLI_ENABLED:false}
        dry-run: ${FLOW_MIGRATION_CLI_DRY_RUN:true}
        include-history: ${FLOW_MIGRATION_CLI_INCLUDE_HISTORY:true}
        fail-on-error: ${FLOW_MIGRATION_CLI_FAIL_ON_ERROR:false}
    worker:
      enabled: ${FLOW_WORKER_ENABLED:true}
      poll-delay: ${FLOW_WORKER_POLL_DELAY:PT0.5S}
      max-concurrency: ${FLOW_WORKER_MAX_CONCURRENCY:1}
      worker-id-prefix: ${FLOW_WORKER_ID_PREFIX:}
    memory:
      window-size: ${CHAT_MEMORY_WINDOW_SIZE:20}
      retention: ${CHAT_MEMORY_RETENTION:PT6H}
      cleanup-interval: ${CHAT_MEMORY_CLEANUP_INTERVAL:PT30M}
    token-usage:
      default-tokenizer: ${CHAT_TOKEN_USAGE_TOKENIZER:cl100k_base}
      cache:
        enabled: ${CHAT_TOKEN_USAGE_CACHE_ENABLED:false}
        ttl: ${CHAT_TOKEN_USAGE_CACHE_TTL:PT15M}
        key-prefix: ${CHAT_TOKEN_USAGE_CACHE_PREFIX:chat:usage}

  telegram:
    enabled: ${TELEGRAM_BOT_ENABLED:false}
    bot:
      token: ${TELEGRAM_BOT_TOKEN:}
      username: ${TELEGRAM_BOT_USERNAME:}
    webhook:
      external-url: ${TELEGRAM_BOT_WEBHOOK_URL:}
      path: ${TELEGRAM_BOT_WEBHOOK_PATH:/telegram/update}
      secret-token: ${TELEGRAM_BOT_WEBHOOK_SECRET:}
      connection-timeout: ${TELEGRAM_BOT_WEBHOOK_TIMEOUT:PT10S}
    allowed-updates: ${TELEGRAM_BOT_ALLOWED_UPDATES:message,callback_query}
    allowed-user-ids: ${TELEGRAM_BOT_ALLOWED_USER_IDS:}
    stt:
      enabled: ${TELEGRAM_STT_ENABLED:true}
      model: ${TELEGRAM_STT_MODEL:gpt-4o-mini-transcribe}
      fallback-model: ${TELEGRAM_STT_FALLBACK_MODEL:}
      language: ${TELEGRAM_STT_LANGUAGE:ru}
