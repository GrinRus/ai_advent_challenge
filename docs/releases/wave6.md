# Wave 6 — Расширенный каталог моделей и биллинг

Дата: 2025-02-11  
Статус: доставлено в `main`, требуются выкладка/миграции

## Ключевые изменения

- **Каталог моделей OpenAI/GLM**  
  Добавлены `gpt-5-nano`, `gpt-4o-mini`, `gpt-5` (OpenAI) и `glm-4-32b-0414-128k` (Zhipu).  
  Конфигурация `app.chat.providers` теперь хранит контекст, лимит вывода, поддержку streaming/structured и цену (USD за 1K токенов).

- **Учёт usage и стоимости**  
  Spring AI метаданные (`ChatResponseMetadata.getUsage()`) конвертируются в токены и стоимость: значения сохраняются в `chat_message` и транслируются в SSE (`event:complete`).  
  Новый эндпоинт `GET /api/llm/sessions/{id}/usage` агрегирует usage/cost по диалогу для аналитики и биллинга.

- **Интерфейс**  
  Фронтенд отображает usage/cost для каждого ответа и итоги по активной сессии. Дополнительно выводятся тарифы/ограничения в выборе модели.

- **Документация и процессы**  
  `docs/infra.md` и `docs/processes.md` описывают актуальные тарифы, ограничения streaming и чек-листы по контролю затрат.

## Сегменты моделей

| Сегмент        | Модели                                | Стоимость (in/out) | Контекст / вывод | Streaming | Рекомендации                                     | Fallback |
|----------------|----------------------------------------|--------------------|------------------|-----------|--------------------------------------------------|----------|
| Economy        | `gpt-5-nano`                           | 0.00005 / 0.0004   | 128K / 8K        | ✅         | фоновые задачи, уведомления, дешёвые проверки     | `gpt-4o-mini` |
| Value          | `gpt-4o-mini`                          | 0.00015 / 0.0006   | 128K / 16K       | ✅         | основной диалог, пользовательские сценарии        | `gpt-5-nano` |
| Flagship       | `gpt-5`                                | 0.00125 / 0.01     | 200K / 32K       | ✅         | аналитика, цепочки reasoning, код-ревью           | `gpt-4o-mini` |
| GLM Alt (sync) | `glm-4-32b-0414-128k` (Zhipu)          | 0.0001 / 0.0001    | 128K / —         | ❌         | длинные документы, flat-pricing, только sync      | `glm-4.6` |

> Источник тарифов: официальные прайс-листы OpenAI (обновление 2024-08/2025-02) и Zhipu (GLM-4 серия).

## План включения

1. **Дефолт** остаётся `gpt-4o-mini` (value-сегмент).  
2. **`gpt-5`** доступна через UI, но включение в прод ограничено лимитами API. Отслеживайте usage и квоты; при превышении переключайтесь на `gpt-4o`.  
3. **`glm-4-32b-0414-128k`** доступна только в синхронном режиме (`/api/llm/chat/sync`). При попытке стриминга возвращается 400.  
4. **Fallback** сценарии реализованы на фронте/бэкенде: при ошибках премиальных моделей UI подсвечивает альтернативы и предлагает `value`/`economy`.

## Контроль затрат

- SSE и синхронные ответы содержат usage/cost; клиент обновляет сводку автоматически.  
- Эндпоинт `GET /api/llm/sessions/{id}/usage` используйте для отчётности и интеграции с биллингом.  
- В `docs/processes.md` добавлен чек-лист: сверка usage с панелями провайдеров, алерты по превышению квот, мониторинг валюты.

## Чек-лист внедрения

1. Прокатить Liquibase-миграцию `0008-add-usage-cost-to-chat-message`.  
2. Проверить переменные окружения для новых моделей (`OPENAI_DEFAULT_MODEL`, `app.chat.providers.*.models`).  
3. Обновить UI до свежей версии (новые блоки usage/cost).  
4. Настроить алерты usage/cost в мониторинге и сверить значения с OpenAI/Zhipu dashboards.  
5. Обновить команды/поддержку: `glm-4-32b-0414-128k` не работает со streaming.  
6. Подготовить rollout коммита в прод с ограничением `gpt-5` (фича-флаг или ручной контроль).
