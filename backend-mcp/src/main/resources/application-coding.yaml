server:
  port: ${CODING_MCP_HTTP_PORT:${SERVER_PORT:8080}}

spring:
  autoconfigure:
    exclude:
      - org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration
      - org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration
      - org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration
      - org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration
      - org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration
  ai:
    mcp:
      server:
        enabled: true
        stdio: false
        protocol: STREAMABLE
        name: coding-mcp
        version: 0.1.0
        type: SYNC
        annotation-scanner:
          enabled: false
        instructions: |
          Coding MCP предоставляет инструменты assisted coding поверх локального workspace:
          • coding.generate_patch — подготовка diff и сохранение патча в реестре.
          • coding.review_patch — эвристическое ревью (риски, тесты, миграции).
          • coding.apply_patch_preview — ручной dry-run (git apply, Docker runner).
          • coding.list_patches — получение списка активных патчей.
          • coding.discard_patch — удаление патча из реестра.
          • coding.generate_artifact — упрощённый генератор файлов через GPT-4o Mini.
        capabilities:
          tool: true
          resource: false
          prompt: false
          completion: false
      streamable-http:
        mcp-endpoint: /mcp
        keep-alive-interval: 30s
    openai:
      enabled: true
      api-key: ${OPENAI_API_KEY:demo-openai-key}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
      chat:
        options:
          model: ${OPENAI_DEFAULT_MODEL:gpt-4o-mini}
          temperature: ${OPENAI_TEMPERATURE:0.3}
          max-tokens: ${OPENAI_MAX_TOKENS:2048}

coding:
  patch-ttl: ${CODING_PATCH_TTL:PT24H}
  max-diff-bytes: ${CODING_MAX_DIFF_BYTES:262144}
  max-context-bytes: ${CODING_MAX_CONTEXT_BYTES:262144}
  claude:
    enabled: ${CODING_CLAUDE_ENABLED:true}
    base-url: ${CODING_CLAUDE_BASE_URL:https://api.z.ai/api/anthropic}
    model: ${CODING_CLAUDE_MODEL:GLM-4.6}
    api-key: ${ZHIPU_API_KEY:}
    max-retries: ${CODING_CLAUDE_MAX_RETRIES:1}
    cli-bin: ${CLAUDE_CODE_BIN:claude}
    cli-timeout: ${CLAUDE_CODE_TIMEOUT:PT2M}
    api-timeout: ${CLAUDE_CODE_API_TIMEOUT:PT50M}
    default-opus-model: ${CLAUDE_CODE_DEFAULT_OPUS_MODEL:GLM-4.6}
    default-sonnet-model: ${CLAUDE_CODE_DEFAULT_SONNET_MODEL:GLM-4.6}
    default-haiku-model: ${CLAUDE_CODE_DEFAULT_HAIKU_MODEL:GLM-4.5-Air}
  openai:
    enabled: ${CODING_OPENAI_ENABLED:true}
    model: ${CODING_OPENAI_MODEL:${OPENAI_DEFAULT_MODEL:gpt-4o-mini}}
    temperature: ${CODING_OPENAI_TEMPERATURE:0.2}
    max-tokens: ${CODING_OPENAI_MAX_TOKENS:2048}
    max-operations: ${CODING_OPENAI_MAX_OPERATIONS:8}
    max-file-lines: ${CODING_OPENAI_MAX_FILE_LINES:2000}
    max-file-bytes: ${CODING_OPENAI_MAX_FILE_BYTES:204800}

logging:
  level:
    org.springframework.ai: DEBUG
    org.springframework.ai.chat: DEBUG
    org.springframework.ai.chat.client: DEBUG
    org.springframework.ai.chat.client.advisor: DEBUG
